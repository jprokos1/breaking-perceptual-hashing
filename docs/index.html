<!DOCTYPE html>
<style>
    .content {
        height: 100%;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        padding-left: 5%;
        padding-right: 5%;
        margin-right: 0px;
        margin-left: 0px;
        font-size: medium;
    }

    .figure {
        margin-bottom: 20px;
        padding-top: 10px;
    }

    .pair {
        display: flex;
        flex-direction: row;
        justify-content: center;
        align-items: center;
        flex-wrap: wrap;
    }

    .pair .figure:first-child {
        padding-right: 5px;
    }

    .pair .figure:last-child {
        padding-left: 5px;
    }
    
    .content h3 {
        text-align: center;
        font-size: 24px;
    }
    
    .content h4 {
        padding-top: 20px;
        font-size: 20px;
    }
    
    .content h5 {
        font-size: 16px;
    }
    
    .figure embed {
        width: 100%;
        height: auto;
        image-rendering: pixelated;
    }
    
    .pair .figure {
        width: 50%;
        height: auto;
    }

    @media only screen and (max-width: 820px) {
        #figures .pair .figure {
            min-width: none;
            width: 100%;
        }
    }

    hr {
        width: 90%;
    }

    p {
        text-indent: 2em;
        max-width: 820px;
    }

    .superscript-icon {
        position: relative;
        display: inline-block;
    }

    .superscript-icon::after {
        position: absolute;
        top: -0.5em;
        /* Adjust this value for vertical positioning */
        font-size: 0.8em;
        /* Adjust this value for the size of the superscript */
    }

    .superscript-icon:hover::after {
        background-color: #f0f0f0;
        /* Add a background color on hover */
        padding: 0.2em;
        /* Add some padding for better visibility */
        border-radius: 4px;
        /* Add rounded corners to the tooltip */
        font-size: 14px;
        /* Adjust the font size of the tooltip text */
        white-space: nowrap;
        /* Prevent the tooltip from breaking into multiple lines */
        display: inline-block;
        /* Display the tooltip on the same line */
        position: absolute;
        top: -2.5em;
        /* Adjust this value to position the tooltip */
        left: 0;
        z-index: 1;
    }
    .superscript-icon.twosix:hover::after {
        content: "Two Six Technologies";
    }
    .superscript-icon.apl:hover::after {
        content: "Johns Hopkins University Applied Physics Laboratory";
    }
    .superscript-icon.post-jhu:hover::after {
        content: "Previously Johns Hopkins University";
    }
    .superscript-icon.jhu:hover::after {
        content: "Johns Hopkins University";
    }
    .superscript-icon.vector-institute:hover::after {
        content: "Vector Institute";
    }
    .superscript-icon.tel-aviv:hover::after {
        content: "Tel Aviv University";
    }
    .superscript-icon.columbia:hover::after {
        content: "Columbia University";
    }
    .superscript-icon.city-ny:hover::after {
        content: "City College of New York";
    }


</style>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Breaking Perceptual Hashing</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css">
</head>

<body>
    <div class="content">
        <div class="page-header">
            <h1>Breaking Perceptual Hashing</h1>
        </div>
        <h3>Based on work presented in <a
                href="https://www.usenix.org/conference/usenixsecurity23/presentation/prokos"><img
                    src="https://www.usenix.org/favicon.ico" style="height: 1em">Squint Hard Enough: <br>Attacking
                Perceptual Hashing with Adversarial Machine Learning</a></h3>
        <!-- *, †, ‡, §, ‖, ¶, ◊, -->
        <h4 style="text-align: center;">Authored by 
            <a href="https://www.ugrad.cs.jhu.edu/~jprokos1/">Jonathan
                Prokos</a><span class="superscript-icon twosix"><sup>*</sup></span><span class="superscript-icon post-jhu"><sup>‡</sup></span>, 
            Neil Fendley<span class="superscript-icon apl"><sup>†</sup></span>, 
            Matthew Green<span class="superscript-icon jhu"><sup>‡</sup></span>,
            <br>
            Roei Schuster<span class="superscript-icon vector-institute"><sup>§</sup></span>,
            Eran Tromer<span class="superscript-icon tel-aviv"><sup>‖</sup></span><span class="superscript-icon columbia"><sup>◊</sup></span>,
            Tushar Jois<span class="superscript-icon city-ny"><sup>¶</sup></span><span class="superscript-icon post-jhu"><sup>‡</sup></span>,
            Yinzhi Cao<span class="superscript-icon jhu"><sup>‡</sup></span>
        </h4>

        <h6 style="text-align: center;">
            <sup>*</sup>Two Six Technologies,
            <sup>†</sup>Johns Hopkins University Applied Physics Laboratory,<br>
            <sup>‡</sup>Johns Hopkins University,
            <sup>§</sup>Vector Institute,
            <sup>‖</sup>Tel Aviv University,
            <sup>◊</sup>Columbia University,
            <sup>¶</sup>City College of New York
        </h6>

        <!-- <h3 style="margin-bottom: 1em">Additional figures and <a href="https://github.com/users/jprokos1/projects/2">changes coming soon</a>. In the meantime view our <a href="https://www.usenix.org/conference/usenixsecurity23/presentation/prokos">USENX paper</a> or associated <a href="#gslides">slides</a>. There are additional results in our <a href="https://eprint.iacr.org/2021/1531.pdf">ePrint archive</a> not included elsewhere.</h3>
        <h4 style="max-width: 90%; padding-top: 0px;">
            In addition to including figures which are not found in our paper, this site will provide an interactive demo of our attack along with the majority of our code. For ethical considerations, we will not be releasing our entire attack code.
        </h4> -->
        <hr>
        <p>
            <span style="font-size: xx-large; line-height: 1">tldr;</span>
            End-to-end (e2e) encrypted messaging systems are becoming increasingly popular. 
            Perceptual hashing is being used to detect illicit content in these systems.
            We show perceptual hashing is vulnerable to adversarial attacks, introducing a side-channel in these e2e systems.
        </p>
        <hr>
        <h3>
            Perceptual hashing?
        </h3>
        <p>
            To start, a <a href="https://en.wikipedia.org/wiki/Hash_function">hash function</a> is a function that takes an arbitrary input of and produces an output of a 
            fixed length.
            This is useful for compressing data or verifying its integrity.
            Most people are familiar with cryptographic hash functions such as <a href="https://en.wikipedia.org/wiki/SHA-256">SHA-256</a> or <a href="https://en.wikipedia.org/wiki/MD5">MD5</a>. Cryptographic hash functions are <em>one-way functions</em> meaning that it is computationally infeasible to find an input that produces a given output. Additionally, these algorithms are designed to be <em>collision resistant</em> meaning that it is computationally infeasible to find two inputs that produce the same output. Perceptual hash functions share neither of these properties.
        </p>

        <!-- <h3>
            Abstract
        </h3>
        <p>
            Many online communications systems use perceptual hash matching systems to detect illicit files in user
            content. These systems employ specialized perceptual hash functions such as Microsoft's PhotoDNA or
            Facebook's PDQ to produce a compact digest of an image file that can be approximately compared to a database
            of known illicit-content digests. Recently, several proposals have suggested that hash-based matching
            systems be incorporated into <em>client-side</em> and end-to-end encrypted (E2EE) systems: in these designs,
            files that register as illicit content will be reported to the provider, while the remaining content will be
            sent confidentially. By using perceptual hashing to determine confidentiality guarantees, this new setting
            significantly changes the function of existing perceptual hashing - thus motivating the need to evaluate
            these functions from an adversarial perspective, using their perceptual capabilities against them. For
            example, an attacker may attempt to trigger a match on innocuous, but politically-charged, content in an
            attempt to stifle speech.
        </p>
        <p>
            In this work we develop threat models for perceptual hashing algorithms in an adversarial setting, and
            present attacks against the two most widely deployed algorithms: PhotoDNA and PDQ. Our results show that it
            is possible to efficiently generate <em>targeted second-preimage attacks</em> in which an attacker creates a
            variant of some source image that matches some target digest. As a complement to this main result, we also
            further investigate the production of images that facilitate <em>detection avoidance attacks</em>,
            continuing a recent investigation of Jain et al. Our work shows that existing perceptual hash functions are
            likely insufficiently robust to survive attacks on this new setting.
        </p> -->
        <hr style="max-width: 820px;">
        <h4>
            Below you can find two gifs showing the progress of our attack over time when utilizing PhotoDNA or PDQ as
            the target perceptual hash function. Attack progression is shown on the left and the target image & its hash
            is shown on the right.
        </h4>
        PhotoDNA
        <div class="pair">
            <div class="figure">
                <embed src="./images/pdna_0.0_0_stacked.gif" width="100%" height="100%" />
            </div>
            <div class="figure">
                <embed src="./images/pdna_0.0_0_tgt.png" width="100%" height="100%" />
                <embed src="./images/pdna_0.0_0_hash_tgt.png" width="100%" height="100%" />
            </div>
        </div>
        PDQ
        <div class="pair">
            <div class="figure">
                <embed src="./images/pdq_4.4_1_stacked.gif" width="100%" height="100%" />
            </div>
            <div class="figure">
                <embed src="./images/pdq_4.4_1_tgt.png" width="100%" height="100%" />
                <embed src="./images/pdq_4.4_1_hash_tgt.png" width="100%" height="100%" />
            </div>
        </div>
        <hr>
        <h3 id="gslides">USENIX Slides (there are speaker notes!)</h3><iframe
            src="https://docs.google.com/presentation/d/e/2PACX-1vTM2IcZFNies45h73hyJYjQ65Ae7ZhCCjcpHbZTIgz8oVvDRwH74hKyTLywbz-g_ss0QCNc9cYDYYJd/embed?start=false&loop=false&delayms=5000"
            frameborder="0" width="1440" height="839" allowfullscreen="true" mozallowfullscreen="true"
            webkitallowfullscreen="true"></iframe>
        <hr>
        <h4>
            The following figures are pulled from our USENIX submission. These will be included in the soon to come
            ePrint update.
        </h4>
        <h5>
            Figure 1 shows the results of our <em>targeted second-preimage attack</em> at both low and high threshold
            levels. Figure 2 shows our <em>detection avoidance attack</em> at the baseline collision threshold as well
            as at a significantly higher threshold. Figures 3 & 4 show the progress of our targeted second-preimage
            attack as the collision threshold is lowered. Figures 5 & 6 show a comparison of the performance of this
            attack using various gradient optimization methods.
        </h5>
        <div class="content" id="figures">
            <div class="pair">
                <div class="figure">
                    <embed src="./images/targeted-second-preimage-collisions.png" />
                </div>
                <div class="figure">
                    <embed src="./images/collision-avoidance.png" />
                </div>
            </div>
            <div class="pair">
                <div class="figure">
                    <embed src="./images/pdna-best.png" />
                </div>
                <div class="figure">
                    <embed src="./images/pdq-best.png" />
                </div>
            </div>
            <div class="pair">
                <div class="figure">
                    <embed src="./images/pdna-attack-variants.png" />
                </div>
                <div class="figure">
                    <embed src="./images/pdq-attack-variants.png" />
                </div>
            </div>
        </div>
    </div>
</body>

</html>