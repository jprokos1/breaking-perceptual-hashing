<!DOCTYPE html>

<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Breaking Perceptual Hashing</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css">
    <link rel="stylesheet" href="./style.css">
</head>

<body>
    <div class="content">
        <div class="page-header">
            <h1 style="font-size: xxx-large;">Breaking Perceptual Hashing</h1>
        </div>
        <h2>Based on work presented in <a
                href="https://www.usenix.org/conference/usenixsecurity23/presentation/prokos"><img
                    src="https://www.usenix.org/favicon.ico" style="height: 1em">Squint Hard Enough: <br>Attacking
                Perceptual Hashing with Adversarial Machine Learning</a></h3>
            <!-- *, †, ‡, §, ‖, ¶, ◊, -->
            <h4 style="text-align: center;">Authored by
                <a href="https://www.ugrad.cs.jhu.edu/~jprokos1/">Jonathan
                    Prokos</a><span class="superscript-icon twosix"><sup>*</sup></span><span
                    class="superscript-icon post-jhu"><sup>‡</sup></span>,
                Neil Fendley<span class="superscript-icon apl"><sup>†</sup></span>,
                Matthew Green<span class="superscript-icon jhu"><sup>‡</sup></span>,
                <br>
                Roei Schuster<span class="superscript-icon vector-institute"><sup>§</sup></span>,
                Eran Tromer<span class="superscript-icon tel-aviv"><sup>‖</sup></span><span
                    class="superscript-icon columbia"><sup>◊</sup></span>,
                Tushar Jois<span class="superscript-icon city-ny"><sup>¶</sup></span><span
                    class="superscript-icon post-jhu"><sup>‡</sup></span>,
                Yinzhi Cao<span class="superscript-icon jhu"><sup>‡</sup></span>
            </h4>

            <h6 style="text-align: center;">
                <sup>*</sup>Two Six Technologies,
                <sup>†</sup>Johns Hopkins University Applied Physics Laboratory,<br>
                <sup>‡</sup>Johns Hopkins University,
                <sup>§</sup>Vector Institute,
                <sup>‖</sup>Tel Aviv University,
                <sup>◊</sup>Columbia University,
                <sup>¶</sup>City College of New York
            </h6>

            <!-- <h3 style="margin-bottom: 1em">Additional figures and <a href="https://github.com/users/jprokos1/projects/2">changes coming soon</a>. In the meantime view our <a href="https://www.usenix.org/conference/usenixsecurity23/presentation/prokos">USENX paper</a> or associated <a href="#gslides">slides</a>. There are additional results in our <a href="https://eprint.iacr.org/2021/1531.pdf">ePrint archive</a> not included elsewhere.</h3>
        <h4 style="max-width: 90%; padding-top: 0px;">
            In addition to including figures which are not found in our paper, this site will provide an interactive demo of our attack along with the majority of our code. For ethical considerations, we will not be releasing our entire attack code.
        </h4> -->
            <hr>
            USENIX Security 2023 Presentation
            <iframe width="560" height="315" src="https://www.youtube.com/embed/v1xeIHyTg-c?si=ebOJl8dwRjGd7vCQ"
                title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                allowfullscreen></iframe>
            <hr>
            <p>
                <span class="parhead">tldr;</span>
                End-to-end (e2e) encrypted messaging systems have become widely adopted.
                In a hurry to provide content moderation, providers have begun using perceptual hash functions to detect
                illicit content.
                However, we show perceptual hashing is vulnerable to adversarial attacks, introducing a side-channel in
                these e2e systems.
            </p>
            <hr>
            <h3>
                What is Perceptual Hashing?
            </h3>
            <p>
                To start, a <a href="https://en.wikipedia.org/wiki/Hash_function">hash function</a> is a function that
                takes arbitrary input and produces an output of a
                fixed length.
                This is useful for compressing data or verifying its integrity.
                Most people are familiar with cryptographic hash functions such as <a
                    href="https://en.wikipedia.org/wiki/SHA-256">SHA-256</a> or <a
                    href="https://en.wikipedia.org/wiki/MD5">MD5</a>. Cryptographic hash functions are <em>one-way
                    functions</em> meaning that it is computationally infeasible to find an input that produces a given
                output. Additionally, these algorithms are designed to be <em>collision resistant</em> meaning that it
                is computationally infeasible to find two inputs that produce the same output. Perceptual hash functions
                (PHF) do not share these cryptographic guarantees.
            </p>
            <p>
                Although we show that perceptual hash functions are vulnerable to adversarial attacks, they are still
                useful for their intended purpose. The perceptual part of the name alludes to its design to embed image
                semantics into the resultant digest. This allows the hash to be locality sensitive. To understand what
                this means, observe the example below:
            </p>
            <span class="figure">
                <img src="images/what-is-phf.svg">
                <div style="font-size:x-small">PHF: <a
                        href="https://en.wikipedia.org/wiki/Perceptual_hashing">Perceptual
                        Hash Function</a> (<a href="https://www.microsoft.com/en-us/photodna">PhotoDNA</a>) | SHA: <a
                        href="https://en/wikipedia.org/wiki/sha2">SHA-256</a>, a <a
                        href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">Cryptographic Hash Function</a>
                </div>
            </span>

            <p>
                The table above shows the input (top) and output (table content) for two types of hash functions (left).
                The input is a set of cat images where <span class="fira">cat1'</span> is an occluded version of <span
                    class="fira">cat1</span> with a red square placed ontop using ms paint.
            </p>
            <p>
                As perceptual hash functions are designed to be locality sensitive, the red square does not affect its
                output much as it is not semantically important. However, the cryptographic hash function is not
                locality sensitive and thus the red square affects its output significantly. This is the key property of
                perceptual hash functions that makes them useful for lots of applications.
            </p>

            <hr>
            <h3>How are PHFs used?</h3>
            <p>
                Cryptographic hash functions - such as SHA-256 shown above - have lots of applications in privacy and
                security. However,
            </p>
            <img src="images/how-is-phf-used.svg">
            <p>
                Imagine the scenario above; client A wants to send an image to client B using some provider (Facebook in
                this example). Before sending this content across its network, the provider will first check the image
                for illicit content.
            </p>
            <p>
                The provider receives the image from client A and computes its perceptual hash. This hash is compared to
                a database of known illicit hashes; if a match is found, the provider will not send the image to client
                B. Otherwise, if no match is found the provider will send the image to client B.
            </p>
            <p>
                This setup works well for detecting known illicit content, but what if we want to capture
                <em>unknown</em> illicit content? To achieve this, providers utilize neural networks to classify any
                arbitrary image as illicit before sending it along to client B.
            </p>

            <p>
                More updates coming soon...
            </p>

            <!-- <h3>
            Abstract
        </h3>
        <p>
            Many online communications systems use perceptual hash matching systems to detect illicit files in user
            content. These systems employ specialized perceptual hash functions such as Microsoft's PhotoDNA or
            Facebook's PDQ to produce a compact digest of an image file that can be approximately compared to a database
            of known illicit-content digests. Recently, several proposals have suggested that hash-based matching
            systems be incorporated into <em>client-side</em> and end-to-end encrypted (E2EE) systems: in these designs,
            files that register as illicit content will be reported to the provider, while the remaining content will be
            sent confidentially. By using perceptual hashing to determine confidentiality guarantees, this new setting
            significantly changes the function of existing perceptual hashing - thus motivating the need to evaluate
            these functions from an adversarial perspective, using their perceptual capabilities against them. For
            example, an attacker may attempt to trigger a match on innocuous, but politically-charged, content in an
            attempt to stifle speech.
        </p>
        <p>
            In this work we develop threat models for perceptual hashing algorithms in an adversarial setting, and
            present attacks against the two most widely deployed algorithms: PhotoDNA and PDQ. Our results show that it
            is possible to efficiently generate <em>targeted second-preimage attacks</em> in which an attacker creates a
            variant of some source image that matches some target digest. As a complement to this main result, we also
            further investigate the production of images that facilitate <em>detection avoidance attacks</em>,
            continuing a recent investigation of Jain et al. Our work shows that existing perceptual hash functions are
            likely insufficiently robust to survive attacks on this new setting.
        </p> -->
            <hr style="max-width: 820px;">
            <h4>
                Below you can find two gifs showing the progress of our attack over time when utilizing PhotoDNA or PDQ
                as
                the target perceptual hash function. Attack progression is shown on the left and the target image & its
                hash
                is shown on the right.
            </h4>
            PhotoDNA
            <div class="pair">
                <div class="figure">
                    <embed src="./images/pdna_0.0_0_stacked.gif" width="100%" height="100%" />
                </div>
                <div class="figure">
                    <embed src="./images/pdna_0.0_0_tgt.png" width="100%" height="100%" />
                    <embed src="./images/pdna_0.0_0_hash_tgt.png" width="100%" height="100%" />
                </div>
            </div>
            PDQ
            <div class="pair">
                <div class="figure">
                    <embed src="./images/pdq_4.4_1_stacked.gif" width="100%" height="100%" />
                </div>
                <div class="figure">
                    <embed src="./images/pdq_4.4_1_tgt.png" width="100%" height="100%" />
                    <embed src="./images/pdq_4.4_1_hash_tgt.png" width="100%" height="100%" />
                </div>
            </div>
            <hr>
            <h3 id="gslides">USENIX Slides (there are speaker notes!)</h3><iframe
                src="https://docs.google.com/presentation/d/e/2PACX-1vTM2IcZFNies45h73hyJYjQ65Ae7ZhCCjcpHbZTIgz8oVvDRwH74hKyTLywbz-g_ss0QCNc9cYDYYJd/embed?start=false&loop=false&delayms=5000"
                frameborder="0" width="1440" height="839" allowfullscreen="true" mozallowfullscreen="true"
                webkitallowfullscreen="true"></iframe>
            <hr>
            <h4>
                The following figures are pulled from our USENIX submission. These will be included in the soon to come
                ePrint update.
            </h4>
            <h5>
                Figure 1 shows the results of our <em>targeted second-preimage attack</em> at both low and high
                threshold
                levels. Figure 2 shows our <em>detection avoidance attack</em> at the baseline collision threshold as
                well
                as at a significantly higher threshold. Figures 3 & 4 show the progress of our targeted second-preimage
                attack as the collision threshold is lowered. Figures 5 & 6 show a comparison of the performance of this
                attack using various gradient optimization methods.
            </h5>
            <div class="content" id="figures">
                <div class="pair">
                    <div class="figure">
                        <embed src="./images/targeted-second-preimage-collisions.png" />
                    </div>
                    <div class="figure">
                        <embed src="./images/collision-avoidance.png" />
                    </div>
                </div>
                <div class="pair">
                    <div class="figure">
                        <embed src="./images/pdna-best.png" />
                    </div>
                    <div class="figure">
                        <embed src="./images/pdq-best.png" />
                    </div>
                </div>
                <div class="pair">
                    <div class="figure">
                        <embed src="./images/pdna-attack-variants.png" />
                    </div>
                    <div class="figure">
                        <embed src="./images/pdq-attack-variants.png" />
                    </div>
                </div>
            </div>
    </div>
</body>

</html>